{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15snMOHrwpWO_qNjB-uqVjM_LwzWq-JuP",
      "authorship_tag": "ABX9TyOC5W6s/848SPQNIa+0bn22",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mistryvivek/A-Level-NEA/blob/main/Model_1_Basic_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9BKFIobTm36L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOupk8NfiXR7",
        "outputId": "bdbbedcb-fe77-477b-c42c-ccccf5e8689c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Weights and Bias.\n",
        "\n",
        "* AI experimental tool."
      ],
      "metadata": {
        "id": "cnr6oqBffyAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU"
      ],
      "metadata": {
        "id": "cA-o8vzff3Y3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log in to your W&B account\n",
        "import wandb\n",
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "3F4388sHf7FM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KY69sdrgAqC",
        "outputId": "dc7ec6d4-9356-4de1-d0a5-deebcd3759a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmistry-vivek03\u001b[0m (\u001b[33mmistry-vivek03-university-of-york\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make RNN"
      ],
      "metadata": {
        "id": "CUHwtkM2f4So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,max_laps,hidden_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding =  nn.Embedding(max_laps, hidden_size)\n",
        "        self.linear_h = nn.Linear(hidden_size,hidden_size)\n",
        "        self.linear_y = nn.Linear(hidden_size,max_laps)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self,x,hprev):\n",
        "        h = self.tanh(self.embedding(x) + self.linear_h(hprev))\n",
        "        y = self.linear_y(h)\n",
        "        return h,y"
      ],
      "metadata": {
        "id": "bWcnkSnqniIl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss function (Based upon wk11 practical)\n",
        "\n",
        "* Vocab size is not relevent here - going to give it binary classification values anyway.\n",
        "* Everything else can be applied for time series: use Cross Entropy Loss, Length of the race = seq_len.\n",
        "* For each lap, pass through the RNN with previous hidden state and build up hte matrix of outputs.\n",
        "* Detact the previous hidden state as a new one will be generated."
      ],
      "metadata": {
        "id": "S81x8lmwJ68-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(model,inputs,targets,hprev,max_tyre_life):\n",
        "  loss_func = nn.BCEWithLogitsLoss()\n",
        "  seq_length = len(inputs)\n",
        "  #outputs = torch.zeros(0, max_laps)\n",
        "  #print(outputs.shape)\n",
        "  for t in range(seq_length):\n",
        "    # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "    hprev,y = model(inputs[t], hprev)\n",
        "    # Gradually build up matrix of output logits of size seq_length * max_tyre_life\n",
        "    #outputs = torch.cat((outputs ,y))\n",
        "\n",
        "  y = y[-1]\n",
        "\n",
        "  # Compute cross entropy loss for seq_length actual targets against estimated distributions\n",
        "  loss = loss_func(y,targets.squeeze(0))\n",
        "\n",
        "  # For truncated backprop, the next subsequence will use the final hidden state\n",
        "  # but will not backprop through it so we need to detach\n",
        "  hprev = hprev.detach()\n",
        "\n",
        "  return loss, hprev"
      ],
      "metadata": {
        "id": "4b01se5zoVVe"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My dataset - how to format?\n",
        "\n",
        "* Training and testing\n",
        "* inputs_training/ inputs_testing/  outputs_testing/ output_training\n",
        "* For now, it will all just be a 2d array.\n",
        "\n",
        "ERROR:\n",
        "\n",
        "```2551     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
        "   2552\n",
        "   2553\n",
        "\n",
        "IndexError: index out of range in self```"
      ],
      "metadata": {
        "id": "icgJLYuiNA2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = r\"/content/drive/MyDrive/prbx_data/v1/\"\n",
        "max_race_size = 0\n",
        "max_tyre_life = 0"
      ],
      "metadata": {
        "id": "vjXV6o1kOB_-"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define compound categories and one-hot encode them\n",
        "compound_categories = ['SOFT', 'MEDIUM', 'HARD', 'WET', 'INTERMEDIATE']\n",
        "compound_encoder = OneHotEncoder(categories=[compound_categories], sparse_output=False)"
      ],
      "metadata": {
        "id": "ugcDXrr65Gdj"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "training_inputs = []\n",
        "training_outputs = []\n",
        "\n",
        "RaceCalender22 = pd.read_csv(BASE_PATH + r\"2022/eventCalender2022.csv\")\n",
        "for _, row in RaceCalender22.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        # Load race data\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2022/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            # Filter data for the specific driver and sort by LapNumber\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            \"\"\"if max(TempRaceLoadDriver['TyreLife']) > max_tyre_life:\n",
        "                max_tyre_life = max(TempRaceLoadDriver['TyreLife'])\"\"\"\n",
        "\n",
        "            # Extract tyre life and stint columns\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "            compound_array = TempRaceLoadDriver['Compound'].values\n",
        "            compound_encoded = compound_encoder.fit_transform(compound_array.reshape(-1, 1))\n",
        "\n",
        "            # Create the stint change array\n",
        "            stint_change_array = []\n",
        "            for i in range(len(stint_array)):\n",
        "                if i == len(stint_array) - 1:  # Last lap\n",
        "                    stint_change_array.append(False)  # Treat as no change\n",
        "                else:\n",
        "                    stint_change_array.append(stint_array[i] != stint_array[i + 1])\n",
        "\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "\n",
        "            # Ensure tyre_life_array and stint_change_array are properly formatted\n",
        "            tyre_life_array = torch.tensor(tyre_life_array, dtype=torch.long, device=device)\n",
        "            compound_encoded = torch.tensor(compound_encoded, dtype=torch.long, device=device)\n",
        "            stint_change_array = torch.tensor(stint_change_array, dtype=torch.float32, device=device)\n",
        "\n",
        "            combined_inputs = torch.cat([tyre_life_array.unsqueeze(1), compound_encoded], dim=1)\n",
        "\n",
        "            # Add to training data\n",
        "            training_inputs.append(combined_inputs)\n",
        "            training_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "ub0zgeNtND3l"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING\n",
        "testing_inputs = []\n",
        "testing_outputs = []\n",
        "\n",
        "RaceCalender23 = pd.read_csv(BASE_PATH + r\"2023/eventCalender2023.csv\")\n",
        "for _, row in RaceCalender23.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        # Load race data\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2023/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            # Filter data for the specific driver and sort by LapNumber\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            if max(TempRaceLoadDriver['TyreLife']) > max_tyre_life:\n",
        "                max_tyre_life = max(TempRaceLoadDriver['TyreLife'])\n",
        "\n",
        "            # Extract tyre life and stint columns\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "            compound_array = TempRaceLoadDriver['Compound'].values\n",
        "            compound_encoded = compound_encoder.fit_transform(compound_array.reshape(-1, 1))\n",
        "\n",
        "            # Create the stint change array\n",
        "            stint_change_array = []\n",
        "            for i in range(len(stint_array)):\n",
        "                if i == len(stint_array) - 1:  # Last lap\n",
        "                    stint_change_array.append(False)  # Treat as no change\n",
        "                else:\n",
        "                    stint_change_array.append(stint_array[i] != stint_array[i + 1])\n",
        "\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "\n",
        "            # Ensure tyre_life_array and stint_change_array are properly formatted\n",
        "            tyre_life_array = torch.tensor(tyre_life_array, dtype=torch.long, device=device)\n",
        "            compound_encoded = torch.tensor(compound_encoded, dtype=torch.long, device=device)\n",
        "            stint_change_array = torch.tensor(stint_change_array, dtype=torch.float32, device=device)\n",
        "\n",
        "            combined_inputs = torch.cat([tyre_life_array.unsqueeze(1), compound_encoded], dim=1)\n",
        "\n",
        "            # Add to testing data\n",
        "            testing_inputs.append(combined_inputs)\n",
        "            testing_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "MQHvjvglTQNF"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n",
        "\n",
        "* https://developers.google.com/machine-learning/crash-course/overfitting/interpreting-loss-curves"
      ],
      "metadata": {
        "id": "4015h9tIT5Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 50\n",
        "lr = 0.001\n",
        "iterations = 10000\n",
        "max_race_size = int(max_race_size)\n",
        "input_parameters = ['TyreLife', 'Compound']\n",
        "dataset = 'v1'"
      ],
      "metadata": {
        "id": "s-1yQVYSUMBf"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(inputs, outputs, tolerance=3):\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for seq_idx in range(len(inputs)):\n",
        "        # Initialize hidden state for each sequence\n",
        "        hprev = torch.zeros(hidden_size, device=device)\n",
        "\n",
        "        # Get the input and target sequences\n",
        "        input = inputs[seq_idx]\n",
        "        output = outputs[seq_idx].cpu().numpy()\n",
        "\n",
        "        # Step through the input sequence and get predicted probabilities\n",
        "        for t in range(len(input)):\n",
        "            hprev, y = model(torch.tensor(input[t], device=device), hprev)\n",
        "            predicted_pits = torch.sigmoid(y) # Apply sigmoid to logits to get probabilities\n",
        "\n",
        "        y = y[-1]\n",
        "\n",
        "        predicted_pits = predicted_pits.cpu().detach().numpy()[0]\n",
        "        predicted_pits = predicted_pits > 0.5\n",
        "        actual_pits = output == 1.0\n",
        "\n",
        "        # Now check accuracy for this sequence with tolerance\n",
        "        correct_count = 0\n",
        "        total_predictions_for_sequence = 0\n",
        "\n",
        "        for predicted_pit_idx in range(len(predicted_pits)):\n",
        "          if predicted_pits[predicted_pit_idx]:  # If a pit stop is predicted\n",
        "              total_predictions += 1\n",
        "\n",
        "              # Calculate the tolerance window around the predicted pit\n",
        "              start_idx = max(0, predicted_pit_idx - tolerance)\n",
        "              end_idx = min(len(actual_pits), predicted_pit_idx + tolerance + 1)\n",
        "\n",
        "              # Check if there's any actual pit stop within this window using NumPy\n",
        "              if np.any(actual_pits[start_idx:end_idx] == 1):  # If there's a pit stop in this window\n",
        "                  correct_count += 1\n",
        "                  break\n",
        "\n",
        "        total_correct += correct_count\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
        "    return accuracy * 100"
      ],
      "metadata": {
        "id": "taRdShcOzWeY"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_with_last_value(tensor, max_race_size):\n",
        "    if len(tensor) >= max_race_size:\n",
        "        return tensor\n",
        "\n",
        "    last_value = tensor[-1]\n",
        "\n",
        "    # TO FIX: RuntimeError: a Tensor with 6 elements cannot be converted to Scalar\n",
        "    # After adding compound\n",
        "    if last_value.ndimension() > 0:\n",
        "        padding = last_value.unsqueeze(0).repeat(max_race_size - len(tensor), 1)\n",
        "    else:\n",
        "        padding = torch.full((max_race_size - len(tensor),), last_value.item(), dtype=tensor.dtype, device=device)\n",
        "\n",
        "    return torch.cat((tensor, padding))"
      ],
      "metadata": {
        "id": "_Km1hhBTVm7G"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(max_race_size, hidden_size)\n",
        "model = model.to(device)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "permutation = torch.randperm(len(training_inputs))\n",
        "training_inputs = [training_inputs[i] for i in permutation]\n",
        "training_outputs = [training_outputs[i] for i in permutation]\n",
        "\n",
        "# Initialize WandB\n",
        "wandb.init(\n",
        "    project=\"prbx-model-v1\",\n",
        "    config={\n",
        "        \"learning_rate\": lr,\n",
        "        \"iterations\": iterations,\n",
        "        \"hidden_size\": hidden_size,\n",
        "        \"max_race_size\": max_race_size,\n",
        "        \"input_parameters\": input_parameters,\n",
        "        \"dataset\": dataset,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"random_perms\": True,\n",
        "    }\n",
        ")\n",
        "\n",
        "n, p = 0, 0\n",
        "while n<=iterations:\n",
        "  hprev = torch.zeros(hidden_size,) # reset RNN memory\n",
        "\n",
        "  inputs = training_inputs[p]\n",
        "  targets = training_outputs[p]\n",
        "\n",
        "  inputs = pad_with_last_value(inputs, max_race_size).to(device)\n",
        "  targets = pad_with_last_value(targets, max_race_size).to(device)\n",
        "  hprev = torch.zeros(hidden_size, device=device)\n",
        "\n",
        "  # Compute loss for current subsequence\n",
        "  loss, hprev = calculate_loss(model,inputs,targets,hprev,max_race_size)\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  if n % 500 == 0:\n",
        "    print('[{:}] Loss: {:.2f}'.format(n,loss.item()))\n",
        "    testing_accuracy = evaluate_model(testing_inputs,testing_outputs)\n",
        "    training_accuracy = evaluate_model(training_inputs,training_outputs)\n",
        "\n",
        "    # Log metrics to WandB\n",
        "    wandb.log({\n",
        "        \"iteration\": n,\n",
        "        \"loss\": loss.item(),\n",
        "        \"training_accuracy\": training_accuracy,\n",
        "        \"testing_accuracy\": testing_accuracy,\n",
        "    })\n",
        "\n",
        "    # Save to weights and biases.\n",
        "    model_path = \"model.pth\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "\n",
        "    artifact = wandb.Artifact(\"basic-rnn-binary-classifier\", type=\"model\")\n",
        "    artifact.add_file(model_path)\n",
        "    wandb.log_artifact(artifact)\n",
        "\n",
        "  n += 1 # iteration counter\n",
        "  p += 1 # dataset counter\n",
        "\n",
        "  #Restart to the front of the list.\n",
        "  if len(training_inputs) - 1 == p:\n",
        "    p = 0\n",
        "    permutation = torch.randperm(len(training_inputs))\n",
        "    training_inputs = [training_inputs[i] for i in permutation]\n",
        "    training_outputs = [training_outputs[i] for i in permutation]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "oxZaedx7T8Ch",
        "outputId": "519ada7a-412b-4108-a93c-1c12475c1193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:tz5cgkpa) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▂▁▂▂▂▂▁▄▃▁▃▁▄▃▁▃▃▂▂▂</td></tr><tr><td>testing_accuracy</td><td>▄▁█▆▁▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_accuracy</td><td>▄▁█▅▁▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>10000</td></tr><tr><td>loss</td><td>0.10264</td></tr><tr><td>testing_accuracy</td><td>0</td></tr><tr><td>training_accuracy</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sleek-sunset-38</strong> at: <a href='https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1/runs/tz5cgkpa' target=\"_blank\">https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1/runs/tz5cgkpa</a><br/> View project at: <a href='https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1' target=\"_blank\">https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 42 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241124_121856-tz5cgkpa/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:tz5cgkpa). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241124_122848-2fhrxlh5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1/runs/2fhrxlh5' target=\"_blank\">misty-capybara-39</a></strong> to <a href='https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1' target=\"_blank\">https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1/runs/2fhrxlh5' target=\"_blank\">https://wandb.ai/mistry-vivek03-university-of-york/prbx-model-v1/runs/2fhrxlh5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Loss: 0.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-187-3f4cf054cb99>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  hprev, y = model(torch.tensor(input[t], device=device), hprev)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[500] Loss: 0.08\n",
            "[1000] Loss: 0.02\n",
            "[1500] Loss: 0.09\n",
            "[2000] Loss: 0.15\n",
            "[2500] Loss: 0.06\n",
            "[3000] Loss: 0.10\n",
            "[3500] Loss: 0.14\n",
            "[4000] Loss: 0.15\n",
            "[4500] Loss: 0.03\n",
            "[5000] Loss: 0.06\n",
            "[5500] Loss: 0.07\n",
            "[6000] Loss: 0.11\n",
            "[6500] Loss: 0.05\n",
            "[7000] Loss: 0.11\n",
            "[7500] Loss: 0.11\n",
            "[8000] Loss: 0.04\n",
            "[8500] Loss: 0.05\n",
            "[9000] Loss: 0.06\n",
            "[9500] Loss: 0.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How can we calculate accuracy for this basic model?\n",
        "\n",
        "* Say is probability is above 80% percent pit, otherwise don't pit.\n",
        "* Want at least one right pit stop identification to class it as match."
      ],
      "metadata": {
        "id": "0LwWuY-xc-c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(len(testing_inputs[1])):\n",
        "  # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "  hprev,y = model(torch.tensor([testing_inputs[1][t]], device=device),hprev)\n",
        "probabilities = torch.sigmoid(y)"
      ],
      "metadata": {
        "id": "Vdeo3NuEsA3b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEWvwpJ2sT2v",
        "outputId": "7a5498c4-285e-4084-d915-0eb1065357f4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.8245e-02, 2.9221e-02, 2.3090e-02, 5.2584e-02, 1.4823e-03, 9.7559e-05,\n",
              "         3.1790e-02, 6.2055e-02, 1.6202e-02, 1.4026e-02, 1.0448e-01, 1.8828e-01,\n",
              "         2.0165e-01, 2.3096e-01, 1.1071e-01, 4.6514e-03, 8.8460e-03, 2.7448e-02,\n",
              "         6.0488e-02, 7.9396e-03, 4.9523e-02, 1.1347e-02, 4.5724e-02, 3.3656e-03,\n",
              "         2.4717e-02, 4.2204e-02, 4.4635e-02, 3.3482e-03, 3.6820e-03, 1.8051e-02,\n",
              "         3.3702e-01, 6.6892e-02, 1.7792e-01, 1.3327e-01, 1.8120e-01, 5.4868e-02,\n",
              "         9.0611e-03, 9.4199e-02, 6.4338e-03, 8.8866e-02, 7.0160e-02, 3.2610e-02,\n",
              "         1.0926e-01, 1.9035e-02, 3.3946e-02, 1.3522e-02, 2.4385e-01, 1.4249e-01,\n",
              "         7.9675e-04, 1.0232e-01, 5.6250e-02, 2.3119e-01, 1.0167e-02, 1.0459e-01,\n",
              "         5.0600e-01, 2.7306e-01, 1.1362e-01, 1.1651e-02, 3.5161e-05, 3.7102e-05,\n",
              "         3.7390e-05, 3.0720e-05, 3.4394e-05, 4.5009e-05, 3.2237e-05, 3.6523e-05,\n",
              "         7.5240e-04, 4.4399e-05, 1.9246e-03, 4.3706e-05, 5.9389e-05, 4.3656e-05,\n",
              "         5.2367e-05, 3.7198e-05, 3.0878e-05, 4.3947e-05, 3.3473e-05, 2.9842e-05]],\n",
              "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(len(training_inputs[0])):\n",
        "  # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "  hprev,y = model(torch.tensor([training_inputs[0][t]], device=device),hprev)\n",
        "probabilities = torch.sigmoid(y)"
      ],
      "metadata": {
        "id": "8Xf23b3VsfGF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxvmEKgxsizL",
        "outputId": "426bd8ef-a392-4c29-b1b0-634235af4b4a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.2579e-01, 1.7864e-02, 9.4681e-03, 1.4281e-04, 1.5162e-01, 5.4269e-03,\n",
              "         2.9113e-03, 1.1016e-04, 1.4941e-01, 2.7708e-03, 9.5839e-03, 2.1853e-02,\n",
              "         1.7905e-02, 2.0627e-02, 8.2723e-02, 4.7361e-02, 7.4057e-03, 3.8286e-02,\n",
              "         1.7217e-01, 3.0808e-02, 1.2943e-05, 5.4943e-02, 9.6523e-02, 1.1784e-01,\n",
              "         2.0476e-01, 1.6795e-02, 2.0350e-03, 5.6160e-04, 5.7783e-02, 1.1220e-01,\n",
              "         1.5802e-03, 3.4600e-02, 1.1455e-01, 2.0244e-02, 2.5614e-03, 8.1257e-03,\n",
              "         5.5695e-02, 3.8255e-02, 4.6864e-01, 3.6415e-03, 4.3508e-04, 1.3077e-04,\n",
              "         7.5569e-03, 9.1153e-03, 7.3553e-02, 1.4736e-02, 1.3291e-02, 4.8492e-03,\n",
              "         1.9084e-03, 3.7519e-03, 1.6917e-02, 1.2566e-03, 2.7801e-03, 2.1017e-02,\n",
              "         2.7895e-04, 1.0429e-02, 1.0856e-03, 5.1355e-03, 5.2290e-06, 5.7702e-06,\n",
              "         5.5054e-06, 5.9562e-06, 5.1920e-06, 5.6708e-06, 5.5325e-06, 6.1476e-06,\n",
              "         1.2775e-04, 6.6866e-06, 5.4204e-04, 4.0143e-06, 6.3745e-06, 5.6179e-06,\n",
              "         8.4090e-06, 5.4181e-06, 3.9626e-06, 5.7377e-06, 7.8686e-06, 5.2275e-06]],\n",
              "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot to see what this basic model has remembered - probably just averages"
      ],
      "metadata": {
        "id": "dTW5sj-0rpEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validating my data"
      ],
      "metadata": {
        "id": "EQrJxg_CXdKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_inputs) == len(training_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i2tG_ZxXEmu",
        "outputId": "c4e770c4-6554-4fae-c36a-6fe43447ce12"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_inputs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT6aLRA5dPL9",
        "outputId": "bf7b532d-7c39-4659-938e-a400b3fae966"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([69])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_outputs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuompqxedSuP",
        "outputId": "43088424-af3f-418e-b5d5-05fb1e20def8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([69])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}